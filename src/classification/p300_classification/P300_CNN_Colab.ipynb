{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6BYdmNQ6yOf"
      },
      "source": [
        "Fz: EXG Channel 2, blue\n",
        "\n",
        "Cz: EXG Channel 7, brown\n",
        "\n",
        "P3: EXG Channel 6, red\n",
        "\n",
        "Pz: EXG Channel 5, orange\n",
        "\n",
        "P4: EXG Channel 4, yellow\n",
        "\n",
        "Column index in csv file: 3, 8, 7, 6, 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq7SInFGW3cw"
      },
      "source": [
        "Total time for each experiment is 60 seconds. Each white image (target) or black image (non-target) appears for 0.5 second.\n",
        "\n",
        "250 Hz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IXWZA0aaW0y"
      },
      "source": [
        "#Data preprocessing#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "mBCthHFJXbuj"
      },
      "outputs": [],
      "source": [
        "TOTAL_TIME = 60\n",
        "IMAGE_TIME = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "5SVPq8MN7lDu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHktmv6w8s3M",
        "outputId": "ceb8a9ab-9b47-4e9d-ee2d-227fb1055583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "d8S7N5Um6IJm"
      },
      "outputs": [],
      "source": [
        "# read CSV file (data)\n",
        "file_path_csv = '/content/drive/My Drive/Colab Notebooks/ece496_p300/BrainFlow-RAW_2023-11-02_16-27-02_67.csv'\n",
        "df = pd.read_csv(file_path_csv, sep='\\t', header=None)\n",
        "\n",
        "# select columns of 5 electrodes\n",
        "Fz_column = df.iloc[:, 3]\n",
        "Cz_column = df.iloc[:, 8]\n",
        "P3_column = df.iloc[:, 7]\n",
        "Pz_column = df.iloc[:, 6]\n",
        "P4_column = df.iloc[:, 5]\n",
        "\n",
        "Fz_array = Fz_column.to_numpy()\n",
        "Cz_array = Cz_column.to_numpy()\n",
        "P3_array = P3_column.to_numpy()\n",
        "Pz_array = Pz_column.to_numpy()\n",
        "P4_array = P4_column.to_numpy()\n",
        "\n",
        "x_array = np.column_stack((Fz_array, Cz_array, P3_array, Pz_array, P4_array))\n",
        "\n",
        "# select column of timestamp and convert unix timestamp to formatted timestamp\n",
        "timestamp_column = df.iloc[:, -2]\n",
        "timestamp_array = timestamp_column.to_numpy()\n",
        "formatted_timestamp_array = [datetime.fromtimestamp(unix_timestamp) for unix_timestamp in timestamp_array]\n",
        "formatted_timestamp_array = [timestamp - timedelta(hours=4) for timestamp in formatted_timestamp_array]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "m_BTDGkdCIvt"
      },
      "outputs": [],
      "source": [
        "#print(x_array.shape)\n",
        "#print(x_array[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "3H5spmLhDtpl"
      },
      "outputs": [],
      "source": [
        "# read TXT file (ground truth)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/ece496_p300/white_time_1.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# initialize lists to store timestamps\n",
        "start_timestamp = None\n",
        "white_timestamps = []\n",
        "\n",
        "# process each line\n",
        "for line in lines:\n",
        "  if \"Recording start at:\" in line:\n",
        "    # extract and convert the absolute start timestamp\n",
        "    start_timestamp_str = line.split(\": \", 1)[1].strip()\n",
        "    start_timestamp = datetime.fromisoformat(start_timestamp_str)\n",
        "  elif \"White image shown at:\" in line:\n",
        "    # extract and convert the relative white image timestamps\n",
        "    white_timestamp_str = line.split(\": \", 1)[1].strip()\n",
        "    hours, minutes, seconds = map(float, white_timestamp_str.split(':'))\n",
        "    white_timestamp = timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
        "    white_timestamps.append(white_timestamp)\n",
        "\n",
        "absolute_white_timestamps = [start_timestamp + delta for delta in white_timestamps]\n",
        "\n",
        "# compute relative white time in seconds\n",
        "white_t = []\n",
        "for i in range(len(white_timestamps)):\n",
        "  white_t.append(white_timestamps[i].seconds + white_timestamps[i].microseconds / 1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "a51NuwEbWp11"
      },
      "outputs": [],
      "source": [
        "#white_timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "dtKcXZ2iTGXQ"
      },
      "outputs": [],
      "source": [
        "#white_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "wxO2clvgHDW7"
      },
      "outputs": [],
      "source": [
        "# label data (0: non-target, 1: target)\n",
        "# Since total time is 60s and each image is 0.5s, there are 120 labels\n",
        "\n",
        "label = [0] * int(TOTAL_TIME / IMAGE_TIME)\n",
        "for t in white_t:\n",
        "  label[round(t / IMAGE_TIME) + 1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "UjFb6rVMT-o5"
      },
      "outputs": [],
      "source": [
        "#len(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "jmXHQrlaSW9N"
      },
      "outputs": [],
      "source": [
        "# Segment data into 120 segments, each corresponding to one label\n",
        "# dataset 1: start from line 1339, timestamp=1698959840.671408 to match start time of white/black image\n",
        "data = []\n",
        "\n",
        "index = 1339\n",
        "for i in range(120):\n",
        "  data_i = [x_array[index:index+125, :], label[i]]\n",
        "  data.append(data_i)\n",
        "  index += 125\n",
        "\n",
        "data = np.array(data, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "e1V6OyRuX-Fd"
      },
      "outputs": [],
      "source": [
        "#data[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffp4ykCTaQff"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "_kSgelvhcTKx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "O_4bxTdtjh0a"
      },
      "outputs": [],
      "source": [
        "# a simple conv net\n",
        "conv1_ksize = (15, 1)\n",
        "conv2_ksize = (1, 5)\n",
        "\n",
        "conv1_isize = 1\n",
        "conv1_osize = 5\n",
        "conv2_isize = conv1_osize\n",
        "conv2_osize = 10\n",
        "\n",
        "fc1_dropout_p = 0.5\n",
        "fc2_dropout_p = 0.5\n",
        "\n",
        "fc1_isize = 1110\n",
        "fc1_osize = 256\n",
        "fc2_isize = fc1_osize\n",
        "fc2_osize = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "uRX8G_Yxd326"
      },
      "outputs": [],
      "source": [
        "class ConvLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, isize, osize, ksize, maxpool=None):\n",
        "\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(isize, osize, ksize),\n",
        "            nn.BatchNorm2d(osize),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # optional maxpool\n",
        "        self.maxpool = None\n",
        "        if maxpool:\n",
        "            self.maxpool = nn.MaxPool2d(maxpool)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        if self.maxpool:\n",
        "            x = self.maxpool(x)\n",
        "        return x\n",
        "\n",
        "class LinearLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, isize, osize, dropout_p, norm=True, activate=True):\n",
        "\n",
        "        super(LinearLayer, self).__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "        self.linear = nn.Linear(isize, osize)\n",
        "        self.batch_norm = nn.BatchNorm1d(osize) if norm else None\n",
        "        self.activate = nn.Tanh() if activate else None\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        if self.batch_norm:\n",
        "            x = self.batch_norm(x)\n",
        "        if self.activate:\n",
        "            x = self.activate(x)\n",
        "        return x\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.in_batch_norm = nn.BatchNorm2d(conv1_isize)\n",
        "        self.feat_extractor = nn.Sequential(\n",
        "            ConvLayer(conv1_isize, conv1_osize, conv1_ksize),\n",
        "            ConvLayer(conv2_isize, conv2_osize, conv2_ksize)\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            LinearLayer(fc1_isize, fc1_osize, fc1_dropout_p),\n",
        "            LinearLayer(fc2_isize, fc2_osize, fc2_dropout_p, norm=False, activate=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.in_batch_norm(x)\n",
        "        x = self.feat_extractor(x)\n",
        "\n",
        "        # flatten the input\n",
        "        batch_size = x.size()[0]\n",
        "        x = x.view(batch_size, -1)\n",
        "\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FImOBiRbgELB"
      },
      "source": [
        "#Load data#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "FD8KNdRpgD2Y"
      },
      "outputs": [],
      "source": [
        "####### main logic #######\n",
        "# load the data\n",
        "# data format: [(x, y)]\n",
        "data_size = len(data)\n",
        "\n",
        "# shuffle data\n",
        "shuffle_idx = np.random.permutation(data_size)\n",
        "data = data[shuffle_idx]\n",
        "\n",
        "# 80-20 split train/test\n",
        "cutoff = int(data_size * 80 // 100)\n",
        "train_data = data[:cutoff]\n",
        "test_data = data[cutoff:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBYqu2IOjGbq",
        "outputId": "ba31ead3-b184-47a5-c90e-3f6fbee52011"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNSMgXQpiaGw",
        "outputId": "29157710-c7d2-4646-ede8-e8ae84b84100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_size, train_data_true_count, train_data_false_count\n",
            "96 17 79\n",
            "test_data_size, test_data_true_count, test_data_false_count\n",
            "24 5 19\n"
          ]
        }
      ],
      "source": [
        "# balance label in the train_data\n",
        "train_data_size = len(train_data)\n",
        "train_data_true_count = np.sum([x[1] for x in train_data])\n",
        "train_data_false_count = train_data_size - train_data_true_count\n",
        "\n",
        "print('train_data_size, train_data_true_count, train_data_false_count')\n",
        "print(train_data_size, train_data_true_count, train_data_false_count)\n",
        "\n",
        "test_data_size = len(test_data)\n",
        "test_data_true_count = np.sum([x[1] for x in test_data])\n",
        "test_data_false_count = test_data_size - test_data_true_count\n",
        "\n",
        "print('test_data_size, test_data_true_count, test_data_false_count')\n",
        "print(test_data_size, test_data_true_count, test_data_false_count)\n",
        "\n",
        "# DON'T NEED TO BALANCE\n",
        "# assert train_data_false_count >= train_data_true_count\n",
        "\n",
        "# train_data_dup_count = train_data_false_count - train_data_true_count\n",
        "# train_data_true_idx = np.array([i for i, x in enumerate(train_data) if x[1] == 1])\n",
        "# train_data_true_sample_idx = np.random.choice(train_data_true_idx, train_data_dup_count, replace=True)\n",
        "# train_data_addon = train_data[train_data_true_sample_idx]\n",
        "\n",
        "# # make sure that all the addon have true labels\n",
        "# assert all([x[1] == 1 for x in train_data_addon])\n",
        "\n",
        "# # stack the addon to the original trainning data and shuffle again\n",
        "# train_data = np.concatenate((train_data, train_data_addon), axis=0)\n",
        "# train_data_size = len(train_data)\n",
        "# shuffle_idx = np.random.permutation(train_data_size)\n",
        "# train_data = train_data[shuffle_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dft4ppU0d80F"
      },
      "source": [
        "#Train#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "lxbi4ZdQd_jX"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "# for debug\n",
        "# np.random.seed(0)\n",
        "\n",
        "# divide data into minibatches\n",
        "def minibatch(data, batch_size):\n",
        "    start = 0\n",
        "    while True:\n",
        "\n",
        "        end = start + batch_size\n",
        "        yield data[start:end]\n",
        "\n",
        "        start = end\n",
        "        if start >= len(data):\n",
        "            break\n",
        "\n",
        "# calculate acc\n",
        "def cal_acc(pred, target):\n",
        "    assert len(pred) == len(target)\n",
        "    acc = np.sum(pred == target) / len(pred)\n",
        "    return acc\n",
        "\n",
        "def cal_f(pred, target):\n",
        "    assert len(pred) == len(target)\n",
        "    tp = 0\n",
        "    for i in range(len(pred)):\n",
        "        if pred[i] == target[i] and pred[i] == 1:\n",
        "            tp += 1\n",
        "    percision = tp / np.sum(pred == 1)\n",
        "    recall = tp / np.sum(target == 1)\n",
        "    f_score = (2 * percision * recall) / (percision + recall)\n",
        "    return f_score, percision, recall\n",
        "\n",
        "# train function\n",
        "def train_batch(model, criterion, optimizer, batch):\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    ##x = torch.FloatTensor([i for i in batch[:, 0]]).cuda()\n",
        "    ##x = torch.FloatTensor([i for i in batch[:, 0]])\n",
        "    x_numpy_array = np.array([i for i in batch[:, 0]])##\n",
        "    x = torch.FloatTensor(x_numpy_array)##\n",
        "    _, height, width = x.size()\n",
        "    x = x.view(min(batch_size, len(x)), 1, height, width)\n",
        "    ##y = torch.FloatTensor([i for i in batch[:, 1]]).cuda()\n",
        "    ##y = torch.FloatTensor([i for i in batch[:, 1]])\n",
        "    y_numpy_array = np.array([i for i in batch[:, 1]])##\n",
        "    y = torch.FloatTensor(y_numpy_array)##\n",
        "    pred = model(x)\n",
        "\n",
        "    # back proporgation\n",
        "    loss = criterion(pred.view(-1), y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    pred = pred.cpu().detach().numpy().reshape(-1)\n",
        "    pred = np.array([1 if n >= 0.5 else 0 for n in pred])\n",
        "    return pred\n",
        "\n",
        "def val_batch(model, criterion, optimizer, batch):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # forward pass\n",
        "        ##x = torch.FloatTensor([i for i in batch[:, 0]]).cuda()\n",
        "        ##x = torch.FloatTensor([i for i in batch[:, 0]])\n",
        "        x_numpy_array = np.array([i for i in batch[:, 0]])##\n",
        "        x = torch.FloatTensor(x_numpy_array)##\n",
        "        _, height, width = x.size()\n",
        "        x = x.view(min(batch_size, len(x)), 1, height, width)\n",
        "        ##y = torch.FloatTensor([i for i in batch[:, 1]]).cuda()\n",
        "        ##y = torch.FloatTensor([i for i in batch[:, 1]])\n",
        "        y_numpy_array = np.array([i for i in batch[:, 1]])##\n",
        "        y = torch.FloatTensor(y_numpy_array)##\n",
        "        pred = model(x)\n",
        "\n",
        "        pred = pred.cpu().detach().numpy().reshape(-1)\n",
        "        pred = np.array([1 if n >= 0.5 else 0 for n in pred])\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tpVcygsMeLuU",
        "outputId": "f1ffa389-d221-4703-d08c-6dea1ca59abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold: 0, epoch: 0, train acc: 0.5402298850574713, val acc: 0.4444444444444444\n",
            "fold: 0, epoch: 1, train acc: 0.5402298850574713, val acc: 0.5555555555555556\n",
            "fold: 0, epoch: 2, train acc: 0.367816091954023, val acc: 0.2222222222222222\n",
            "fold: 0, epoch: 3, train acc: 0.4942528735632184, val acc: 0.5555555555555556\n",
            "fold: 0, epoch: 4, train acc: 0.42528735632183906, val acc: 0.3333333333333333\n",
            "fold: 0, epoch: 5, train acc: 0.5517241379310345, val acc: 0.6666666666666666\n",
            "fold: 0, epoch: 6, train acc: 0.45977011494252873, val acc: 0.6666666666666666\n",
            "fold: 0, epoch: 7, train acc: 0.4482758620689655, val acc: 0.3333333333333333\n",
            "fold: 0, epoch: 8, train acc: 0.45977011494252873, val acc: 0.6666666666666666\n",
            "fold: 0, epoch: 9, train acc: 0.45977011494252873, val acc: 0.4444444444444444\n",
            "fold: 0, test acc: 0.20833333333333334\n",
            "fold: 0, test percision: 0.20833333333333334, test recall: 1.0, test f score: 0.3448275862068966\n",
            "fold: 1, epoch: 0, train acc: 0.5287356321839081, val acc: 0.6666666666666666\n",
            "fold: 1, epoch: 1, train acc: 0.5057471264367817, val acc: 0.4444444444444444\n",
            "fold: 1, epoch: 2, train acc: 0.5057471264367817, val acc: 0.6666666666666666\n",
            "fold: 1, epoch: 3, train acc: 0.5402298850574713, val acc: 0.5555555555555556\n",
            "fold: 1, epoch: 4, train acc: 0.5402298850574713, val acc: 0.7777777777777778\n",
            "fold: 1, epoch: 5, train acc: 0.4942528735632184, val acc: 0.7777777777777778\n",
            "fold: 1, epoch: 6, train acc: 0.5862068965517241, val acc: 0.6666666666666666\n",
            "fold: 1, epoch: 7, train acc: 0.5747126436781609, val acc: 0.4444444444444444\n",
            "fold: 1, epoch: 8, train acc: 0.5057471264367817, val acc: 0.7777777777777778\n",
            "fold: 1, epoch: 9, train acc: 0.5632183908045977, val acc: 0.5555555555555556\n",
            "fold: 1, test acc: 0.75\n",
            "fold: 1, test percision: 0.4444444444444444, test recall: 0.8, test f score: 0.5714285714285714\n",
            "fold: 2, epoch: 0, train acc: 0.45977011494252873, val acc: 0.7777777777777778\n",
            "fold: 2, epoch: 1, train acc: 0.5172413793103449, val acc: 0.5555555555555556\n",
            "fold: 2, epoch: 2, train acc: 0.5057471264367817, val acc: 0.3333333333333333\n",
            "fold: 2, epoch: 3, train acc: 0.5172413793103449, val acc: 0.6666666666666666\n",
            "fold: 2, epoch: 4, train acc: 0.5172413793103449, val acc: 0.3333333333333333\n",
            "fold: 2, epoch: 5, train acc: 0.5402298850574713, val acc: 0.5555555555555556\n",
            "fold: 2, epoch: 6, train acc: 0.5057471264367817, val acc: 0.5555555555555556\n",
            "fold: 2, epoch: 7, train acc: 0.5862068965517241, val acc: 0.5555555555555556\n",
            "fold: 2, epoch: 8, train acc: 0.5402298850574713, val acc: 0.5555555555555556\n",
            "fold: 2, epoch: 9, train acc: 0.6091954022988506, val acc: 0.6666666666666666\n",
            "fold: 2, test acc: 0.75\n",
            "fold: 2, test percision: 0.4444444444444444, test recall: 0.8, test f score: 0.5714285714285714\n",
            "fold: 3, epoch: 0, train acc: 0.45977011494252873, val acc: 0.3333333333333333\n",
            "fold: 3, epoch: 1, train acc: 0.5977011494252874, val acc: 0.5555555555555556\n",
            "fold: 3, epoch: 2, train acc: 0.5517241379310345, val acc: 0.8888888888888888\n",
            "fold: 3, epoch: 3, train acc: 0.5862068965517241, val acc: 0.6666666666666666\n",
            "fold: 3, epoch: 4, train acc: 0.5747126436781609, val acc: 0.7777777777777778\n",
            "fold: 3, epoch: 5, train acc: 0.4827586206896552, val acc: 0.6666666666666666\n",
            "fold: 3, epoch: 6, train acc: 0.5747126436781609, val acc: 0.5555555555555556\n",
            "fold: 3, epoch: 7, train acc: 0.5402298850574713, val acc: 0.4444444444444444\n",
            "fold: 3, epoch: 8, train acc: 0.47126436781609193, val acc: 0.8888888888888888\n",
            "fold: 3, epoch: 9, train acc: 0.5057471264367817, val acc: 0.4444444444444444\n",
            "fold: 3, test acc: 0.7083333333333334\n",
            "fold: 3, test percision: 0.4, test recall: 0.8, test f score: 0.5333333333333333\n",
            "fold: 4, epoch: 0, train acc: 0.5057471264367817, val acc: 0.4444444444444444\n",
            "fold: 4, epoch: 1, train acc: 0.47126436781609193, val acc: 0.4444444444444444\n",
            "fold: 4, epoch: 2, train acc: 0.5287356321839081, val acc: 0.6666666666666666\n",
            "fold: 4, epoch: 3, train acc: 0.5517241379310345, val acc: 0.6666666666666666\n",
            "fold: 4, epoch: 4, train acc: 0.5862068965517241, val acc: 0.4444444444444444\n",
            "fold: 4, epoch: 5, train acc: 0.4942528735632184, val acc: 0.5555555555555556\n",
            "fold: 4, epoch: 6, train acc: 0.5862068965517241, val acc: 0.3333333333333333\n",
            "fold: 4, epoch: 7, train acc: 0.5977011494252874, val acc: 0.4444444444444444\n",
            "fold: 4, epoch: 8, train acc: 0.5632183908045977, val acc: 0.4444444444444444\n",
            "fold: 4, epoch: 9, train acc: 0.5517241379310345, val acc: 0.4444444444444444\n",
            "fold: 4, test acc: 0.75\n",
            "fold: 4, test percision: 0.4444444444444444, test recall: 0.8, test f score: 0.5714285714285714\n",
            "fold: 5, epoch: 0, train acc: 0.47126436781609193, val acc: 0.5555555555555556\n",
            "fold: 5, epoch: 1, train acc: 0.5057471264367817, val acc: 0.6666666666666666\n",
            "fold: 5, epoch: 2, train acc: 0.6091954022988506, val acc: 0.5555555555555556\n",
            "fold: 5, epoch: 3, train acc: 0.5862068965517241, val acc: 0.3333333333333333\n",
            "fold: 5, epoch: 4, train acc: 0.5517241379310345, val acc: 0.3333333333333333\n",
            "fold: 5, epoch: 5, train acc: 0.5632183908045977, val acc: 0.5555555555555556\n",
            "fold: 5, epoch: 6, train acc: 0.5862068965517241, val acc: 0.6666666666666666\n",
            "fold: 5, epoch: 7, train acc: 0.5632183908045977, val acc: 0.5555555555555556\n",
            "fold: 5, epoch: 8, train acc: 0.5517241379310345, val acc: 0.3333333333333333\n",
            "fold: 5, epoch: 9, train acc: 0.5977011494252874, val acc: 0.5555555555555556\n",
            "fold: 5, test acc: 0.7916666666666666\n",
            "fold: 5, test percision: 0.5, test recall: 0.8, test f score: 0.6153846153846154\n",
            "fold: 6, epoch: 0, train acc: 0.5977011494252874, val acc: 0.5555555555555556\n",
            "fold: 6, epoch: 1, train acc: 0.5402298850574713, val acc: 0.6666666666666666\n",
            "fold: 6, epoch: 2, train acc: 0.6091954022988506, val acc: 0.4444444444444444\n",
            "fold: 6, epoch: 3, train acc: 0.5632183908045977, val acc: 0.6666666666666666\n",
            "fold: 6, epoch: 4, train acc: 0.5632183908045977, val acc: 0.4444444444444444\n",
            "fold: 6, epoch: 5, train acc: 0.5977011494252874, val acc: 0.5555555555555556\n",
            "fold: 6, epoch: 6, train acc: 0.5517241379310345, val acc: 0.4444444444444444\n",
            "fold: 6, epoch: 7, train acc: 0.5517241379310345, val acc: 0.7777777777777778\n",
            "fold: 6, epoch: 8, train acc: 0.5172413793103449, val acc: 0.4444444444444444\n",
            "fold: 6, epoch: 9, train acc: 0.5747126436781609, val acc: 0.4444444444444444\n",
            "fold: 6, test acc: 0.7916666666666666\n",
            "fold: 6, test percision: 0.5, test recall: 0.8, test f score: 0.6153846153846154\n",
            "fold: 7, epoch: 0, train acc: 0.5287356321839081, val acc: 0.6666666666666666\n",
            "fold: 7, epoch: 1, train acc: 0.5517241379310345, val acc: 0.5555555555555556\n",
            "fold: 7, epoch: 2, train acc: 0.5172413793103449, val acc: 0.6666666666666666\n",
            "fold: 7, epoch: 3, train acc: 0.5517241379310345, val acc: 0.7777777777777778\n",
            "fold: 7, epoch: 4, train acc: 0.6436781609195402, val acc: 0.7777777777777778\n",
            "fold: 7, epoch: 5, train acc: 0.5517241379310345, val acc: 0.6666666666666666\n",
            "fold: 7, epoch: 6, train acc: 0.5632183908045977, val acc: 0.6666666666666666\n",
            "fold: 7, epoch: 7, train acc: 0.6091954022988506, val acc: 0.7777777777777778\n",
            "fold: 7, epoch: 8, train acc: 0.6091954022988506, val acc: 0.7777777777777778\n",
            "fold: 7, epoch: 9, train acc: 0.5172413793103449, val acc: 0.7777777777777778\n",
            "fold: 7, test acc: 0.75\n",
            "fold: 7, test percision: 0.4444444444444444, test recall: 0.8, test f score: 0.5714285714285714\n",
            "fold: 8, epoch: 0, train acc: 0.5402298850574713, val acc: 0.5555555555555556\n",
            "fold: 8, epoch: 1, train acc: 0.5402298850574713, val acc: 0.4444444444444444\n",
            "fold: 8, epoch: 2, train acc: 0.5402298850574713, val acc: 0.5555555555555556\n",
            "fold: 8, epoch: 3, train acc: 0.5402298850574713, val acc: 0.7777777777777778\n",
            "fold: 8, epoch: 4, train acc: 0.5172413793103449, val acc: 0.6666666666666666\n",
            "fold: 8, epoch: 5, train acc: 0.5287356321839081, val acc: 0.6666666666666666\n",
            "fold: 8, epoch: 6, train acc: 0.6206896551724138, val acc: 0.5555555555555556\n",
            "fold: 8, epoch: 7, train acc: 0.5287356321839081, val acc: 0.7777777777777778\n",
            "fold: 8, epoch: 8, train acc: 0.5977011494252874, val acc: 0.6666666666666666\n",
            "fold: 8, epoch: 9, train acc: 0.6896551724137931, val acc: 0.6666666666666666\n",
            "fold: 8, test acc: 0.7916666666666666\n",
            "fold: 8, test percision: 0.5, test recall: 0.8, test f score: 0.6153846153846154\n",
            "fold: 9, epoch: 0, train acc: 0.5057471264367817, val acc: 0.5555555555555556\n",
            "fold: 9, epoch: 1, train acc: 0.5632183908045977, val acc: 0.5555555555555556\n",
            "fold: 9, epoch: 2, train acc: 0.5172413793103449, val acc: 0.2222222222222222\n",
            "fold: 9, epoch: 3, train acc: 0.5862068965517241, val acc: 0.5555555555555556\n",
            "fold: 9, epoch: 4, train acc: 0.4942528735632184, val acc: 0.6666666666666666\n",
            "fold: 9, epoch: 5, train acc: 0.5057471264367817, val acc: 0.4444444444444444\n",
            "fold: 9, epoch: 6, train acc: 0.5747126436781609, val acc: 0.5555555555555556\n",
            "fold: 9, epoch: 7, train acc: 0.5172413793103449, val acc: 0.6666666666666666\n",
            "fold: 9, epoch: 8, train acc: 0.5517241379310345, val acc: 0.6666666666666666\n",
            "fold: 9, epoch: 9, train acc: 0.5977011494252874, val acc: 0.5555555555555556\n",
            "fold: 9, test acc: 0.7916666666666666\n",
            "fold: 9, test percision: 0.5, test recall: 0.8, test f score: 0.6153846153846154\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6a4b3031-38e5-4ea9-a2ae-7a09f7dbae99\", \"model_fold_10_epoch_10_bs_128.pth\", 1154370)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch = 10\n",
        "\n",
        "# init model\n",
        "model = ConvNet()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5 * 2, weight_decay=1e-2)\n",
        "\n",
        "# train loop\n",
        "# use k-fold validation\n",
        "k_fold = 10\n",
        "fold_size = int(train_data_size // k_fold)\n",
        "for i in range(k_fold):\n",
        "\n",
        "    # split data into train/val\n",
        "    val_data_curr_fold = train_data[i*fold_size:(i+1)*fold_size]\n",
        "    train_data_curr_fold_head = train_data[:i*fold_size]\n",
        "    train_data_curr_fold_tail = train_data[(i+1)*fold_size:]\n",
        "    train_data_curr_fold = np.concatenate((train_data_curr_fold_head, train_data_curr_fold_tail))\n",
        "\n",
        "    # epoch\n",
        "    model = model.train()\n",
        "    for curr_epoch in range(epoch):\n",
        "\n",
        "        # train minibatch\n",
        "        train_pred = []\n",
        "        train_data_curr_fold = train_data_curr_fold[np.random.permutation(len(train_data_curr_fold))]\n",
        "        for b in minibatch(train_data_curr_fold, batch_size):\n",
        "            train_batch_pred = train_batch(model, criterion, optimizer, b)\n",
        "            train_pred.append(train_batch_pred)\n",
        "        train_pred = np.concatenate(train_pred, axis=0)\n",
        "\n",
        "        val_pred = []\n",
        "        for b in minibatch(val_data_curr_fold, batch_size):\n",
        "            val_batch_pred = val_batch(model, criterion, optimizer, b)\n",
        "            val_pred.append(val_batch_pred)\n",
        "        val_pred = np.concatenate(val_pred, axis=0)\n",
        "\n",
        "        # calculate acc\n",
        "        train_target = train_data_curr_fold[:, 1].reshape(-1)\n",
        "        train_acc = cal_acc(train_pred, train_target)\n",
        "        val_target = val_data_curr_fold[:, 1].reshape(-1)\n",
        "        val_acc = cal_acc(val_pred, val_target)\n",
        "\n",
        "        # print stats\n",
        "        print(f\"fold: {i}, epoch: {curr_epoch}, train acc: {train_acc}, val acc: {val_acc}\")\n",
        "\n",
        "    # test acc\n",
        "    model = model.eval()\n",
        "    test_pred = []\n",
        "    for b in minibatch(test_data, batch_size):\n",
        "        test_batch_pred = val_batch(model, criterion, optimizer, b)\n",
        "        test_pred.append(test_batch_pred)\n",
        "    test_pred = np.concatenate(test_pred, axis=0)\n",
        "    test_target = test_data[:, 1].reshape(-1)\n",
        "    test_acc = cal_acc(test_pred, test_target)\n",
        "    test_f_score, test_percision, test_recall = cal_f(test_pred, test_target)\n",
        "    print(f\"fold: {i}, test acc: {test_acc}\")\n",
        "    print(f\"fold: {i}, test percision: {test_percision}, test recall: {test_recall}, test f score: {test_f_score}\")\n",
        "\n",
        "    if i == k_fold - 1:##\n",
        "        # Save the model after the first fold\n",
        "        model_save_path = f'/content/drive/My Drive/Colab Notebooks/cnn-p300/models/model_fold_{i+1}_epoch_{epoch}_bs_{batch_size}.pth'##\n",
        "        torch.save(model.state_dict(), model_save_path)##\n",
        "\n",
        "        torch.save(model.state_dict(), f'model_fold_{i+1}_epoch_{epoch}_bs_{batch_size}.pth')##\n",
        "        from google.colab import files##\n",
        "        files.download(f'model_fold_{i+1}_epoch_{epoch}_bs_{batch_size}.pth')##\n",
        "\n",
        "    #     break##"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
